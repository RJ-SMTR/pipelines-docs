{"config":{"lang":["pt"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Documenta\u00e7\u00e3o das pipelines, ferramentas e nomenclaturas de dados da SMTR","text":"<p>Seja bem-vindo(a) \u00e0 nossa documenta\u00e7\u00e3o!</p> <p>Se quiser contribuir com nossos projetos siga os links abaixo:</p> <p>Reposit\u00f3rio documenta\u00e7\u00e3o</p> <p>Reposit\u00f3rio pipelines</p> <p>Guia de boas pr\u00e1ticas do Escrit\u00f3rio de dados</p> <p>Datalake da prefeitura</p> <p></p>"},{"location":"ambientes/","title":"Ambientes","text":""},{"location":"ambientes/#desenvolvimento","title":"Desenvolvimento","text":"<p>\u00c9 o ambiente de testes dos pipelines e modelos do DBT, deve ser passado atrav\u00e9s da label <code>RJ_SMTR_DEV_AGENT_LABEL</code> nos pipelines que est\u00e3o sendo desenvolvidos e como <code>rj-smtr-dev</code> no campo <code>database</code> no arquivo <code>sources.yml</code> dos modelos do DBT.</p>"},{"location":"ambientes/#producao","title":"Produ\u00e7\u00e3o","text":"<p>\u00c9 o ambiente de produ\u00e7\u00e3o dos pipelines e modelos do DBT, deve ser passado atrav\u00e9s da label <code>RJ_SMTR_AGENT_LABEL</code> nos pipelines que est\u00e3o sendo desenvolvidos e como <code>rj-smtr-staging</code> no campo <code>database</code> no arquivo <code>sources.yml</code> dos modelos do DBT.</p> <p>Corresponde \u00e0 branch <code>main</code> do reposit\u00f3rio do github.</p>"},{"location":"datacleanrooms/","title":"Datacleanrooms","text":""},{"location":"datacleanrooms/#como-fixar-o-projeto-no-bigquery","title":"Como fixar o projeto no bigquery","text":"<ul> <li>Abra o console do Bigquery</li> <li>No lado esquerdo da tela, clique no \u00edcone de b\u00fassola (Explorador) como mostrado na imagem abaixo; em seguida clique em \"Adicionar dados\"</li> <li></li> <li>Na nova aba que ser\u00e1 aberta do lado direito da tela, na parte inferior, clique em \"Marcar um projeto com estrela por nome\"</li> <li>Quando solicitado o nome do projeto, adicione \"rj-smtr\"</li> <li>Clique no \u00edcone ao lado da b\u00fassola (Explorador)</li> <li>Agora, sempre que abrir o seu console, o projeto aberto de produ\u00e7\u00e3o da SMTR estar\u00e1 vis\u00edvel para explora\u00e7\u00e3o<ul> <li>Caso n\u00e3o esteja aparecendo, atualize a sua p\u00e1gina com F5 e/ou clique no seletor \"Mostrar apenas com estrela\"</li> </ul> </li> </ul>"},{"location":"datacleanrooms/#como-fazer-a-inscricao-subscribe-nos-data-clean-rooms-da-smtr","title":"Como fazer a inscri\u00e7\u00e3o (subscribe) nos Data Clean Rooms da SMTR","text":"<ul> <li>Ao entrar no console do Bigquery, passe o mouse no canto direito da tela para abrir o menu lateral como mostra a imagem abaixo:</li> <li></li> <li>Clique em \"Compartilhamento (Analytics Hub)\", caso esteja usando o console em ingl\u00eas, esse bot\u00e3o se chamar\u00e1 \"Sharing\"</li> <li>Ao ser direcionado para a pagina inicial do Analytics Hub, clique em pesquisar listagens</li> <li></li> <li>Na aba que ser\u00e1 aberta, em \"Filtros\", selecione \"Data clean rooms\". Ap\u00f3s selecionar este filtro, a pesquisa deve retornar os Data Clean Rooms compartilhados com seu usu\u00e1rio</li> <li>Clique em \"Inscrever-se\"</li> <li>A partir de agora, no projeto que estava selecionado no momento da inscri\u00e7\u00e3o, voc\u00ea dever\u00e1 encontrar um dataset com o mesmo nome da Clean Room na qual voc\u00ea se inscreveu<ul> <li>Dentro desse dataset, voc\u00ea deve conseguir ver as tabelas que foram compartilhadas dentro do Clean Room</li> <li>Dados compartilhados em Data Clean Rooms, normalmente s\u00e3o protegidos por regras de an\u00e1lise, para mais informa\u00e7\u00f5es, leia o tutorial</li> </ul> </li> </ul>"},{"location":"datasets/","title":"Datasets","text":""},{"location":"datasets/#descricao","title":"Descri\u00e7\u00e3o","text":"<p>Datasets s\u00e3o cont\u00eaineres para organiza\u00e7\u00e3o e controle de acesso de tabelas e views no BigQuery.</p> <p>O nome do dataset deve ser o mesmo na defini\u00e7\u00e3o do pipeline e na pasta de modelos do DBT.</p>"},{"location":"datasets/#dataset-sources","title":"Dataset Sources","text":"<p>Os dataset utilizados na captura de dados brutos devem seguir o seguinte padr\u00e3o ao serem nomeados:</p> <p><code>[dataset_id]_[fonte]_source (ex.: cadastro_jae_source)</code></p>"},{"location":"datasets/#datasets-atuais","title":"Datasets atuais","text":"<ul> <li>gtfs:</li> </ul> <p>Dados de planejamento da malha de transporte da cidade. Tabelas no formato padr\u00e3o GTFS (General Transport Feed Specification).</p> <ul> <li>cadastro:</li> </ul> <p>Dados cadastrais de recursos f\u00edsicos e humanos do sistema de transporte da cidade.</p> <ul> <li>monitoramento:</li> </ul> <p>Dados de frequ\u00eancia cont\u00ednua (minuto, di\u00e1rio, outros) sobre a opera\u00e7\u00e3o de transportes na cidade.</p> <ul> <li>financeiro:</li> </ul> <p>Dados de movimenta\u00e7\u00f5es financeiras do sistema de transporte da cidade.</p> <ul> <li>bilhetagem:</li> </ul> <p>Dados de componentes e recursos do sistema de bilhetagem da cidade.</p> <ul> <li>subsidio:</li> </ul> <p>Dados de componentes e recursos do sistema de subs\u00eddio da cidade.</p> <ul> <li>sustentabilidade:</li> </ul> <p>Dados e indicadores de mobilidade sustent\u00e1vel da cidade.</p>"},{"location":"ferramentas/","title":"Ferramentas","text":""},{"location":"ferramentas/#python","title":"Python","text":"<p>Utilizamos a vers\u00e3o 3.10.13 do Python para cria\u00e7\u00e3o e execu\u00e7\u00e3o dos pipelines.</p> <p>Documenta\u00e7\u00e3o: https://docs.python.org/pt-br/3.10/</p>"},{"location":"ferramentas/#prefect","title":"Prefect","text":"<p>Utilizamos a vers\u00e3o 1.4.1 do Prefect para cria\u00e7\u00e3o dos pipelines.</p> <p>Documenta\u00e7\u00e3o: https://docs-v1.prefect.io/api/latest/</p>"},{"location":"ferramentas/#dbt","title":"DBT","text":"<p>Utilizamos a vers\u00e3o 1.7.3 do DBT para cria\u00e7\u00e3o dos modelos.</p> <p>Documenta\u00e7\u00e3o: https://docs.getdbt.com/docs/introduction</p>"},{"location":"ferramentas/#bigquery","title":"BigQuery","text":"<p>Utilizamos o Biquery para armazenamento das tabelas intermedi\u00e1rias e materializadas.</p> <p>Documenta\u00e7\u00e3o: https://cloud.google.com/bigquery/docs/reference/rest</p>"},{"location":"ferramentas/#google-cloud-storage","title":"Google Cloud Storage","text":"<p>O GCS \u00e9 utilizado para armazenas os dados brutos gerados nas pipelines de captura, principalmente.</p> <p>Documenta\u00e7\u00e3o: https://cloud.google.com/storage/docs?hl=pt-br</p>"},{"location":"ferramentas/#infisical","title":"Infisical","text":"<p>O Infisical \u00e9 utilizado para cria\u00e7\u00e3o e armazenamento de tokens e segredos.</p> <p>Documenta\u00e7\u00e3o: https://infisical.com/docs/documentation/getting-started/introduction</p>"},{"location":"pastas_arquivos/","title":"Pastas e arquivos","text":""},{"location":"pastas_arquivos/#estrutura-de-diretorios","title":"Estrutura de diret\u00f3rios","text":"<pre><code>\u251c\u2500\u2500 pipelines\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 nome_dataset_projeto # diret\u00f3rio de projeto\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 flows.py # declara\u00e7\u00e3o dos flows\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py # obrigat\u00f3rio para que o python reconhe\u00e7a como pacote, pode estar vazio\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 tasks.py # declara\u00e7\u00e3o das tasks\n\u2502\u00a0\u00a0 |   \u251c\u2500\u2500 schedules.py # declara\u00e7\u00e3o de schedules\n|   |   \u2514\u2500\u2500 utils.py  # fun\u00e7\u00f5es auxiliares\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 constants.py # valores constantes\n|   \u251c\u2500\u2500 templates\n|   \u2502\u00a0\u00a0 \u251c\u2500\u2500 flows.py # flows gen\u00e9ricos\n|   \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py # inicia o pacote\n|   |\u00a0\u00a0 \u2514\u2500\u2500 tasks.py # tasks gen\u00e9ricas\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 utils\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 __init__.py # inicia o pacote\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 secret.py # fun\u00e7\u00f5es para acessar tokens e secrets necess\u00e1rios\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 utils.py # fun\u00e7\u00f5es auxiliares \n\u251c\u2500\u2500 queries\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dbt_project.yml # configura\u00e7\u00f5es do dbt e dos modelos\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 dev\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 __init__.py # inicia o pacote\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 profiles-example.yml # arquivo de exemplo para cria\u00e7\u00e3o do profiles.yml\n|   |   \u251c\u2500\u2500 profiles.yml # criado localmente, cont\u00e9m configura\u00e7\u00f5es para teste local\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 run.py # arquivo de teste local dos modelos dbt\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 utils.py # fun\u00e7\u00f5es auxiliares do dbt\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 macros\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 nome_macro.sql # scripts que podem ser reutilizados v\u00e1rias vezes (similar a uma fun\u00e7\u00e3o)\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 models\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 nome_dataset\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 nome_modelo.sql # instru\u00e7\u00f5es sql para materializa\u00e7\u00e3o de uma tabela ou view\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 schema.yml # estrutura e documenta\u00e7\u00e3o do modelo\n\u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 sources.yml # fonte dos modelos DBT\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 profiles.yml # configura\u00e7\u00e3o do ambiente cloud\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 tests # arquivos para testar a qualidade dos dados\n\u2514\u2500\u2500 README.md # descri\u00e7\u00e3o do reposit\u00f3rio\n\n\n</code></pre>"},{"location":"quick_start/","title":"Quick Start","text":""},{"location":"quick_start/#configuracao-de-ambiente-para-desenvolvimento","title":"Configura\u00e7\u00e3o de ambiente para desenvolvimento","text":""},{"location":"quick_start/#requisitos","title":"Requisitos","text":"<ul> <li>Um editor de texto (recomendado VS Code)</li> <li>Python 3.10.x</li> <li><code>pip</code></li> <li>(Opcional, mas recomendado) Um ambiente virtual para desenvolvimento (<code>miniconda</code>, <code>virtualenv</code> ou similares)</li> </ul>"},{"location":"quick_start/#procedimentos","title":"Procedimentos","text":"<ul> <li>Clonar esse reposit\u00f3rio:</li> </ul> <pre><code>git clone https://github.com/prefeitura-rio/pipelines_rj_smtr\n</code></pre> <ul> <li>Criar um ambiente virtual com venv:</li> </ul> <pre><code>python -m venv ./venv \n</code></pre> <ul> <li>Ativar o ambiente:</li> </ul> <pre><code>source venv/bin/activate\n</code></pre> <p>Obs.: Essa maneira de criar o ambiente virtual presume que voc\u00ea j\u00e1 tenha a vers\u00e3o correta do python, caso voc\u00ea tenha uma vers\u00e3o diferente do Python, utilize outro tipo de gerenciador de ambientes, como <code>anaconda</code>, <code>miniconda</code>, <code>pyenv</code> ou <code>virtualenv</code>.</p> <ul> <li> <p>Abra-o no seu editor de texto</p> </li> <li> <p>No seu ambiente de desenvolvimento, instalar poetry para gerenciamento de depend\u00eancias:</p> </li> </ul> <pre><code>pip3 install poetry\n</code></pre> <ul> <li>Instalar as depend\u00eancias para desenvolvimento:</li> </ul> <pre><code>poetry install\n</code></pre> <ul> <li>Instalar os hooks de pr\u00e9-commit:</li> </ul> <pre><code>pre-commit install\n</code></pre> <ul> <li>Pode ser necess\u00e1rio rodar manualmente o pre-commit pela primeira vez.</li> </ul> <p>Obs.: o comando abaixo serve para ambientes Linux.</p> <pre><code> bash .git/hooks/pre-commit \n</code></pre> <p>Ou:</p> <pre><code>pre-commit run\n</code></pre> <ul> <li>Pronto! Seu ambiente est\u00e1 configurado para desenvolvimento.</li> </ul>"},{"location":"quick_start/#como-testar-uma-pipeline-localmente","title":"Como testar uma pipeline localmente","text":"<p>Escolha a pipeline que deseja executar (exemplo, <code>pipelines.rj_escritorio.template_pipeline.flows.flow</code>):</p> <pre><code>from pipelines.utils.utils import run_local\npipelines.rj_escritorio.template_pipeline.flows import flow\n\nrun_local(flow, parameters = {\"param\": \"val\"})\n</code></pre>"},{"location":"quick_start/#como-testar-uma-pipeline-na-nuvem","title":"Como testar uma pipeline na nuvem","text":"<ol> <li>Configure as vari\u00e1veis de ambiente num arquivo chamado <code>.env</code> na raiz    do projeto:</li> </ol> <pre><code>GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json  # Credenciais do Google Cloud\nPREFECT__BACKEND=cloud\nPREFECT__SERVER__HOST=https://prefect.dados.rio/api\nPREFECT__SERVER__PORT=443\nVAULT_ADDRESS=https://vault.dados.rio/\nVAULT_TOKEN=&lt;token&gt; # Valor do token do \u00f3rg\u00e3o para o qual voc\u00ea est\u00e1 desenvolvendo. Caso n\u00e3o saiba o token, entre em contato.\n</code></pre> <ul> <li> <p><code>source .env</code></p> </li> <li> <p>Tamb\u00e9m garanta que o arquivo <code>$HOME/.prefect/auth.toml</code> exista e tenha um conte\u00fado semelhante a:</p> </li> </ul> <pre><code># This file is auto-generated and should not be manually edited\n# Update the Prefect config or use the CLI to login instead\n\n[\"prefect.dados.rio\"]\napi_key = \"&lt;sua-api-key&gt;\"\ntenant_id = \"&lt;tenant-id&gt;\"\n</code></pre> <ul> <li> <p>Em seguida, tenha certeza que voc\u00ea j\u00e1 tem acesso \u00e0 UI do Prefect, tanto para realizar a submiss\u00e3o da run, como para   acompanh\u00e1-la durante o processo de execu\u00e7\u00e3o. Caso n\u00e3o tenha, verifique o procedimento em https://library-emd.herokuapp.com/infraestrutura/como-acessar-a-ui-do-prefect</p> </li> <li> <p>Crie o arquivo <code>test.py</code> com a pipeline que deseja executar e adicione a fun\u00e7\u00e3o <code>run_cloud</code>    com os par\u00e2metros necess\u00e1rios:</p> </li> </ul> <pre><code>from pipelines.utils import run_cloud\nfrom pipelines.[secretaria].[pipeline].flows import flow # Complete com as infos da sua pipeline\n\nrun_cloud(\n    flow,               # O flow que voc\u00ea deseja executar\n    labels=[\n        \"example\",      # Label para identificar o agente que ir\u00e1 executar a pipeline (ex: rj-sme)\n    ],\n    parameters = {\n        \"param\": \"val\", # Par\u00e2metros que ser\u00e3o passados para a pipeline (opcional)\n    }\n)\n</code></pre> <ol> <li>Rode a pipeline com:</li> </ol> <pre><code>python test.py\n</code></pre> <p>A sa\u00edda deve se assemelhar ao exemplo abaixo:</p> <pre><code>[2022-02-19 12:22:57-0300] INFO - prefect.GCS | Uploading xxxxxxxx-development/2022-02-19t15-22-57-694759-00-00 to datario-public\nFlow URL: http://localhost:8080/default/flow/xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n \u2514\u2500\u2500 ID: xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n \u2514\u2500\u2500 Project: main\n \u2514\u2500\u2500 Labels: []\nRun submitted, please check it at:\nhttp://prefect-ui.prefect.svc.cluster.local:8080/flow-run/xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\n</code></pre> <ul> <li>(Opcional, mas recomendado) Quando acabar de desenvolver sua pipeline, delete todas as vers\u00f5es da mesma pela UI do Prefect.</li> </ul>"},{"location":"pipelines/novos_pipelines/","title":"Novos pipelines","text":""},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v1/","title":"Apura\u00e7\u00e3o de viagens (SPPO) [1.0]","text":"<ul> <li>Queries</li> <li> <p>Pipelines</p> </li> <li> <p>Vers\u00e3o: 2.0.0</p> </li> <li>Data de in\u00edcio: 01/06/2022</li> </ul>"},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v1/#etapas","title":"Etapas","text":""},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v1/#1-atualizacao-de-viagens-planejadas","title":"1. Atualiza\u00e7\u00e3o de viagens planejadas","text":"<p>Os servi\u00e7os e trajetos considerados no subs\u00eddio s\u00e3o atualizados pela equipe de Planejamento, podendo ser inclu\u00eddas novas linhas, alteradas rotas ou mesmo a quilometragem determinada. Essa rotina acontece a cada quinzena de apura\u00e7\u00e3o do subs\u00eddio.</p> <p>Como resultado, obtemos para cada dia de apura\u00e7\u00e3o o quadro planejado por trajeto, conforme exemplo abaixo. Nele, consolidamos:</p> <ol> <li>A dist\u00e2ncia planejada para cada viagem (<code>distancia_planejada</code>, ou extens\u00e3o do trajeto) e total por dia (<code>distancia_total_planejada</code>)</li> </ol> <p></p> <ol> <li>A geometria do trajeto (<code>shape</code>), assim como seu ponto inicial    (<code>start_pt</code>) e final (<code>end_pt</code>),    que ser\u00e3o usados para identificar as posi\u00e7\u00f5es de GPS na pr\u00f3xima    etapa.</li> </ol> <p></p> <p>Observa\u00e7\u00f5es:</p> <ul> <li> <p>Os trajetos circulares t\u00eam seu shape dividido em ida e volta, para   possibilitar a identifica\u00e7\u00e3o da viagem. Nestes casos, a coluna   <code>shape_id_planejado</code> recebe o id \"te\u00f3rico\" e <code>shape_id</code> recebe o ID   de ida ou volta, trocando-se 11\u00ba caractere do ID [ex: 866 -   <code>O0866AAA0ACDU01</code> (te\u00f3rico) x <code>O0866AAA0AIDU01</code> (ida)].</p> </li> <li> <p>O <code>tipo_dia</code> determina a quilometragem total planejada para aquele dia, conforme o Plano Operacional. Caso o dia seja um feriado, o <code>tipo_dia</code> considerado ser\u00e1 de Domingo. Caso seja ponto facultativo, ser\u00e1 usado <code>Sabado</code>.</p> </li> <li> <p>Nesta vers\u00e3o, os hor\u00e1rios de <code>inicio_periodo</code> e <code>fim_periodo</code> s\u00e3o desconsiderados e consideramos o planejado para o dia inteiro.</p> </li> </ul>"},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v1/#2-calculo-de-viagens-realizadas","title":"2. C\u00e1lculo de viagens realizadas","text":"<p>O c\u00e1lculo \u00e9 realizado cruzando sinais de GPS com o trajeto planejado de cada servi\u00e7o. Em resumo, identifica-se potenciais viagens a partir de posi\u00e7\u00f5es do GPS emitidas nos pontos inicial e final do trajeto, e depois valida-se a viagem caso atinja os percentuais de conformidade m\u00ednimos de:</p> <ul> <li>Cobertura de GPS: 50% dos minutos entre o in\u00edcio e fim da viagem devem ter pelo menos 1 sinal de GPS;</li> <li>Cobertura do trajeto: 80% das posi\u00e7\u00f5es de GPS devem ter sido identificadas dentro   do trajeto planejado (num raio de 500m);</li> </ul> <p>O passo a passo do algoritmo est\u00e1 descrito abaixo.</p> <p>Vamos seguir um exemplo com o \u00f4nibus B63050 (<code>id_veiculo</code>) no servi\u00e7o <code>349</code> ao longo da metodologia para facilitar a explica\u00e7\u00e3o. </p>"},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v1/#21-classificacao-das-posicoes-de-gps-no-trajeto-aux_registros_status_trajeto","title":"2.1. Classifica\u00e7\u00e3o das posi\u00e7\u00f5es de GPS no trajeto (<code>aux_registros_status_trajeto</code>)","text":"<p>As posi\u00e7\u00f5es de GPS dos \u00f4nibus s\u00e3o capturadas a cada minuto, e posteriormente tratadas a cada hora na tabela <code>gps_sppo</code>. A partir dos dados de GPS, sabemos para cada ve\u00edculo (<code>id_veiculo</code>, ou n\u00famero de ordem) e datahora (<code>timestamp_gps</code>), qual era sua posi\u00e7\u00e3o (<code>latitude</code>, <code>longitude</code>) e o servi\u00e7o no qual estava operando (<code>servico</code>) naquele momento.</p> <p>Para o dia 24/06, recebemos as seguintes informa\u00e7\u00f5es por GPS do B63050 de 6:15 \u00e0s 6:16: </p> <p>Cruzamos essa tabela de posi\u00e7\u00f5es de GPS com o trajeto (<code>shape</code>) da <code>viagem_planejada</code> pela data e servi\u00e7o para classificar cada posi\u00e7\u00e3o como:</p> <ul> <li><code>start</code>: ve\u00edculo estava no ponto inicial do trajeto (num raio de 500m)</li> <li><code>end</code>: ponto final do trajeto (num raio de 500m)</li> <li><code>middle</code>: meio do trajeto (num raio de 500m)</li> <li><code>out</code>: fora do trajeto (num raio de 500m)</li> </ul> <p>Nesta etapa, as posi\u00e7\u00f5es s\u00e3o duplicadas para os trajetos de ida (<code>I</code>) e volta (<code>V</code>) pois ainda n\u00e3o temos como dizer qual sentido o ve\u00edculo est\u00e1 operando.</p> <p>Uma vez classificado o <code>status_viagem</code>, obtemos para o mesmo intervalo de 6:15 \u00e0s 6:16: </p>"},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v1/#22-identificacao-de-inicio-e-fim-de-viagens-aux_viagem_inicio_fim-aux_viagem_circular","title":"2.2. Identifica\u00e7\u00e3o de in\u00edcio e fim de viagens (<code>aux_viagem_inicio_fim</code>, <code>aux_viagem_circular</code>)","text":"<p>Uma vez classificadas as posi\u00e7\u00f5es, buscamos os pares de in\u00edcio e fim que possivelmente formam uma viagem.</p> <p>Para isso, identificamos a \"movimenta\u00e7\u00e3o\" do ve\u00edculo: qual \u00e9 seu <code>status_viagem</code> naquele momento e qual era seu <code>status_viagem</code> imediatamente anterior. Classificamos, ent\u00e3o, como in\u00edcio da viagem (<code>datetime_partida</code>) o momento em que o ve\u00edculo sai do ponto inicial e entra no trajeto, isto \u00e9, movimenta\u00e7\u00e3o = <code>startmiddle</code>. Da mesma forma, o fim da viagem \u00e9 classificado como o momento em que o ve\u00edculo chega no ponto final a partir do trajeto, isto \u00e9, movimenta\u00e7\u00e3o = <code>middleend</code>.</p> <p>Na se\u00e7\u00e3o anterior vimos que o B63050 esteve no ponto inicial (<code>start</code>) do trajeto de volta (<code>V</code>) \u00e0s 6:15:26 e logo em seguida, \u00e0s 6:15:56, esteve no meio do trajeto (<code>middle</code>). Logo, 6:15:26 \u00e9 potencialmente o in\u00edcio de uma viagem no servi\u00e7o 349. Para afirmarmos isso, deve haver posteriormente uma movimenta\u00e7\u00e3o <code>middleend</code>, que \u00e9 observada \u00e0s 7:20:57. Realizando esse processo ao longo do dia 24/06, obtemos as seguintes poss\u00edveis viagens do B63050: </p> <p>Realizamos um tratamento final nessa etapa para juntar as viagens circulares, separadas nos trajetos de ida (<code>I</code>) e volta (<code>V</code>), na tabela <code>aux_viagem_circular</code>. O in\u00edcio de uma viagem circular (<code>datetime_partida</code>) corresponde ao in\u00edcio do trajeto de ida e o final da viagem (<code>datetime_chegada</code>) ao final do trajeto de volta.</p>"},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v1/#23-classificacao-das-posicoes-de-gps-nas-viagens-registros_status_viagem","title":"2.3. Classifica\u00e7\u00e3o das posi\u00e7\u00f5es de GPS nas viagens (<code>registros_status_viagem</code>)","text":""},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v1/#24-calculo-dos-percentuais-de-conformidade-da-viagem-viagem_conformidade-viagem_completa","title":"2.4. C\u00e1lculo dos percentuais de conformidade da viagem (<code>viagem_conformidade</code>, <code>viagem_completa</code>)","text":""},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v10/","title":"Apuracao viagens v10","text":""},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v10/#glossario","title":"Gloss\u00e1rio:","text":"<ul> <li>Dist\u00e2ncia aferida: C\u00e1lculo da dist\u00e2ncia percorrida entre dois pontos de dados de GPS sucessivos.</li> <li>Garagem: Local onde os ve\u00edculos de transporte ficam quando n\u00e3o est\u00e3o em opera\u00e7\u00e3o.</li> <li>GTFS: Arquivo contendo informa\u00e7\u00f5es sobre linhas de \u00f4nibus e servi\u00e7os de BRT da cidade do Rio de Janeiro. Atualizado mensalmente pela Secretaria Municipal de Transportes https://www.data.rio/datasets/8ffe62ad3b2f42e49814bf941654ea6c/about</li> <li>id_veiculo: Identifica\u00e7\u00e3o do ve\u00edculo a partir de um n\u00famero de ordem.</li> <li>id_viagem: Identifica\u00e7\u00e3o \u00fanica para cada viagem</li> <li>Modelo ephemeral e incremental: Vide DBT (https://docs.getdbt.com/docs/build/materializations)</li> <li>Plano operacional: Documento divulgado pelo site https://transportes.prefeitura.rio que cont\u00e9m as caracter\u00edsticas operacionais dos servi\u00e7os.</li> <li>Ponto: Comunica\u00e7\u00e3o pontual do GPS.</li> <li>Rota planejada: Rota planejada para aquele tipo de servi\u00e7o e sentido conforme o GTFS.</li> <li>Rota realizada: Rota realizada pelo ve\u00edculo em determinado tipo de servi\u00e7o, sentido, data, hor\u00e1rio</li> <li>Servi\u00e7o: Codifica\u00e7\u00e3o alfanum\u00e9rica que possui itiner\u00e1rio pr\u00e9-definido e especifica\u00e7\u00e3o de quilometragem. </li> <li>Shape - Elemento geom\u00e9trico que representa o espa\u00e7o em formato linestring ou multilinestring.</li> <li>Timestamp - Registro de data e hora</li> <li>Viagem - O percurso completo de um ve\u00edculo, partindo de um ponto inicial e terminando em um ponto final, com determinado hor\u00e1rio de in\u00edcio e t\u00e9rmino[duas meias viagens].</li> <li>Viagem Circular - Viagens que o in\u00edcio e o fim do trajeto possuem a mesma geolocaliza\u00e7\u00e3o. </li> </ul>"},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v10/#1-tabela-gps_sppo","title":"1. Tabela: gps_sppo","text":"<ul> <li>Defini\u00e7\u00e3o: A tabela gps_sppo \u00e9 onde s\u00e3o armazenados os dados do gps ap\u00f3s passar pelas seguintes transforma\u00e7\u00f5es de c\u00e1lculo da velocidade instant\u00e2nea,  c\u00e1lculo da velocidade m\u00e9dia, an\u00e1lise se o ve\u00edculo encontra-se parado, conformidade com a rota. </li> </ul> <p>1.1 C\u00e1lculo da velocidade instant\u00e2nea [velocidade_instantanea] - A velocidade instant\u00e2nea \u00e9 calculada dividindo a dist\u00e2ncia percorrida pelo tempo entre dois registros de timestamp consecutivos.  - O resultado \u00e9 ent\u00e3o multiplicado por 3,6 para converter a unidade para km/h.</p> <p>1.2 C\u00e1lculo da velocidade m\u00e9dia [velocidade_estimada_10_min] - Modelo ephemeral [sppo_aux_registros_velocidade.sql] - A velocidade m\u00e9dia \u00e9 zerada quando h\u00e1 qualquer altera\u00e7\u00e3o de ve\u00edculo ou servi\u00e7o. - A velocidade m\u00e9dia \u00e9 calculada a partir da m\u00e9dia das velocidades dos \u00faltimos 10 minutos (declarado no modelo como 600 seconds). - Antes de completar os 10 minutos, a velocidade m\u00e9dia permanece igual a zero. - Caso a velocidade exceda 60 km/h (sendo um outlier), ela ser\u00e1 ajustada para 60 km/h.</p> <p>1.3 Ve\u00edculo parado [tipo_parada] - Modelo ephemeral [sppo_aux_registros_parada] - Ve\u00edculo recebe o status quo de parado quando a velocidade entre dois pontos \u00e9 igual a 0km/h. - Velocidade limiar parada: 3km/h O ve\u00edculo poder\u00e1 estar parado pr\u00f3ximos a terminais (dentro de um raio de 250m) ou dentro da garagem. Esta defini\u00e7\u00e3o permite rotular as observa\u00e7\u00f5es da coluna tipo_parada como \"Em opera\u00e7\u00e3o\", \"Parado garagem\"</p> <p>1.4 Rota - Modelo ephemeral [sppo_aux_registros_flag_trajeto_correto] - Etapa que objetiva analisar se o ve\u00edculo realizou o trajeto correto, conforme as shapes (camadas georreferenciadas) dos trajetos e dos trajetos alternativos.  - A partir da utiliza\u00e7\u00e3o do window_function o modelo calcula um indicador de quantas vezes o ve\u00edculo esteve dentro do trajeto correto. - A condi\u00e7\u00e3o de trajeto correto \u00e9 atingida se o ve\u00edculo estiver dentro da vari\u00e1vel buffer_segmento_metros (500 metros). </p> <p>1.5 Linhagem do dado</p> <ul> <li></li> </ul> <p>1.6 Exemplo da Tabela</p> <ul> <li></li> </ul>"},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v10/#2-tabela-registros_status_viagem","title":"2. Tabela: registros_status_viagem","text":"<p>Caminho queries/models/projeto_subsidio_sppo/registro_status_viagem</p> <ul> <li>Objetivo: processamento do status da viagem (start, middle, end, out)</li> </ul> <p>2.1 Tratamento das viagens com servi\u00e7o caracterizado como circular - Modelo ephemeral:aux_viagem_circular - Caminho queries/models/projeto_subsidios_sppo/aux_viagem_circular.sql - Esse modelo ephemeral consulta o modelo aux_viagem_inicio_fim para filtrar apenas as viagens com sentido = \"C\", o objetivo \u00e9 selecionar para essa an\u00e1lise apenas as viagens circulares. - Ao utilizar a window function LEAD o modelo identifica o pr\u00f3ximo registro de determinado ve\u00edculo e servi\u00e7o dentro de uma janela de tempo. - flag_proximo_volta se for igual a TRUE e o sentido do shape for igual a \"I\" (Ida) e o datetime chegada for menor ou igual ao datetime partida volta gera um resultado que garante que o trajeto que representa a ida de uma viagem circular com sua volta logo em seguida. - O modelo, ao realizar o particionamento de ida e volta, garante que ambos sentidos recebam o mesmo id_viagem. - Ap\u00f3s o tratamento das viagens circulares, o modelo concatena as viagens usando \"union all\" que n\u00e3o t\u00eam os servi\u00e7os circulares. </p> <p>2.2 Processamento - Modelo ephemeral: aux_registros_status_trajeto - Caminho queries/models/projeto_subsidios_sppo/aux_registros_status_trajeto.sql</p> <ul> <li>O objetivo desse modelo \u00e9 verificar se o ve\u00edculo est\u00e1 em rota e, em caso positivo, verificar qual indicador de posi\u00e7\u00e3o o ve\u00edculo est\u00e1.</li> <li>Indicador de posi\u00e7\u00e3o:<ul> <li>start: o ve\u00edculo est\u00e1 pr\u00f3ximo ao in\u00edcio da rota.</li> <li>middle: a viagem e o ve\u00edculo recebem o status de middle a partir da primeira comunica\u00e7\u00e3o depois do buffer inicial (start).</li> <li>end: o ve\u00edculo encontra-se pr\u00f3ximo ao final da rota</li> <li>out: ve\u00edculo fora da rota.</li> </ul> </li> <li>Vide ilustra\u00e7\u00e3o esquem\u00e1tica:</li> <li> <p></p> </li> <li> <p>Vari\u00e1vel buffer geogr\u00e1fico {{ var(\"buffer\") }} define o quanto o ve\u00edculo precisa estar pr\u00f3ximo a rota para que o trajeto seja considerado v\u00e1lido ( Atualmente o buffer est\u00e1 declarado como 500 metros)</p> </li> <li>Fun\u00e7\u00e3o determin\u00edstica para valida\u00e7\u00e3o do indicador de posi\u00e7\u00e3o - ST_DWITHIN.</li> <li>Caso especial (janela temporal): eventos como o show da Madonna requerem ajuste de par\u00e2emtros como do buffer geogr\u00e1fico ou sele\u00e7\u00f5es de tipos de servi\u00e7o.</li> <li>Correspond\u00eancia do tipo de servi\u00e7o: o modelo analisa que se o servi\u00e7o informado via GPS est\u00e1 igual ao servi\u00e7o planejado. </li> <li>Resumo de valida\u00e7\u00e3o da viagem:</li> <li>Indicador de posi\u00e7\u00e3o (start, middle, end): a comunica\u00e7\u00e3o do GPS deve acontecer nas tr\u00eas inst\u00e2ncias do indicador de posi\u00e7\u00e3o.</li> <li>O servi\u00e7o planejado deve ser igual ao servi\u00e7o informado.</li> </ul> <p>(Verificar se \u00e9 nesse trecho que instancio a faixa hor\u00e1ria)</p> <p>2.3 Modelo de tabela: registros_status_viagem</p> <ul> <li></li> </ul> <p>2.4 Linhagem da tabela registro_status_viagem</p> <ul> <li></li> </ul>"},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v10/#3-tabela-viagem-completa","title":"3. Tabela: viagem completa","text":"<ul> <li>Caminho queries/models/projeto_subsidio_sppo/viagem_completa.sql</li> <li>Esse modelo acessa tr\u00eas tabelas, sendo os itens 3.1 Viagem Planejada e 3.2 Viagem Conformidade e a Tabela de Shapes proveniente do GTFS.</li> <li>O objetivo dessa tabela \u00e9 consolidar informa\u00e7\u00f5es para cada viagem de dist\u00e2ncia planejada e dist\u00e2ncia aferida, tempo de viagem, n\u00famero de registros da comunica\u00e7\u00e3o do GPS e apresentar o percentual de conformidade.</li> <li>Regra de neg\u00f3cio: O ve\u00edculo para estar em conformidade, deve no m\u00ednimo comunicar em 80% do trajeto planejado, sendo que uma comunica\u00e7\u00e3o deve ser no star e outra no end..</li> <li>Modelo da tabela</li> <li> </li> <li>Linhagem da tabela</li> <li> </li> </ul> <p>3.1 Tabela Viagem planejada - Modelo incremental: viagem_planejada.sql - Caminho queries/models/projeto_subsidio_sppo/viagem_planejada.sql - O objetivo dessa consulta para a gera\u00e7\u00e3o do modelo viagem completa \u00e9 gerar uma tabela de viagens planejadas para o per\u00edodo apurado.</p> <p>3.1.1 Modelo Tabela -  3.1.2 Linhagem da tabela viagem planejada</p> <ul> <li></li> </ul> <p>3.2 Viagem conformidade - Modelo incremental: viagem_conformidade.sql - Caminho queries/models/projeto_subsidio_sppo/viagem_conformidade.sql - O objetivo dessa tabela que alimenta a tabela viagem completa \u00e9 gerar uma tabela de viagens que analisa as conformidades conforme o planejado - Esse modelo acessa os modelos ef\u00eameros listados no item:   * 2.1 Item aux_viagem_circular - Esse modelo consulta o modelo ephemeral aux_viagem_registros (3.2.1).</p> <pre><code> **3.2.1 aux_viagem_registro**\n - Modelo ephemeral: aux_viagem_registros.sql\n - Caminho queries/models/projeto_subsidio_sppo/ aux_viagem_registros.sql\n - Os principais objetivos desse modelo s\u00e3o:\n   * medir a quantidade de registros;\n   * medir a dist\u00e2ncia entre o in\u00edcio e fim do trecho;\n   * contar registros de comunica\u00e7\u00f5es do GPS no indicador de posi\u00e7\u00e3o (2.2): start, middle, end.\n</code></pre> <p>3.2.2 Modelo Tabela Viagem Conformidade - </p> <ul> <li>3.2.3 Linhagem da Tabela viagem conformidade</li> <li></li> </ul> <p>4. Tabela subsidio_data_versao_efetiva - Modelo Incremental: subsidio_data_versao_efetiva.sql - Caminho queries/models/projeto_subsidio_sppo/subsidio_data_versao_efetiva.sql - O objetivo desse modelo \u00e9 criar um calend\u00e1rio operacional, classificando os tipos de dia como:   * Dia \u00fatil,   * S\u00e1bado,   * Domingo,   * Ponto Facultativo. - O modelo faz a classifica\u00e7\u00e3o por subtipo de dia, classificados como:   * Ver\u00e3o,   * E eventos como (Show da Madonna, Rock in Rio, Concurso P\u00fablico Unificado (CNU), Elei\u00e7\u00e3o. - O modelo capta a \u00faltima data_versao, considerando um intervalo de 30 dias, que consta nas tabelas trips, shapes e frequencies. - No modelo atual h\u00e1 especifica\u00e7\u00e3o de datas at\u00edpicas, como eventos na cidade. - Aten\u00e7\u00e3o para a vari\u00e1vel: {var('DATA_SUBSIDIO_**_INICIO')- Declarada no dbt_project com datas importantes. </p> <p>4.1 Modelo de tabela</p> <p>4.2 Linhagem do dado</p> <ul> <li>Processamento de Hor\u00e1rios (quadro):</li> <li>Realiza um JOIN com a tabela de hor\u00e1rios planejados (subsidio_quadro_horario) para associar as viagens aos hor\u00e1rios corretos.</li> <li> <p>Converte os hor\u00e1rios de in\u00edcio e fim (inicio_periodo e fim_periodo) para objetos datetime.</p> </li> <li> <p>Integra\u00e7\u00e3o de Dados das Viagens (trips):</p> </li> <li> <p>Faz um JOIN com a tabela de trips (subsidio_trips_desaninhada), aplicando filtros com base nas vers\u00f5es espec\u00edficas para garantir que os dados planejados sejam alinhados corretamente.</p> </li> <li> <p>Ajustes dos IDs das Trips (quadro_trips):</p> </li> <li> <p>Ajusta os IDs das trips com base na dire\u00e7\u00e3o do trajeto (sentido), criando identificadores \u00fanicos que diferenciam as trips de ida, volta e circular, quando aplic\u00e1vel.</p> </li> <li> <p>Combina\u00e7\u00e3o de Trips e Shapes (quadro_tratada):</p> </li> <li>Integra os dados das trips ajustadas com os shapes das rotas, combinando os trip_id planejados e reais para garantir a ader\u00eancia entre o planejamento e a execu\u00e7\u00e3o.</li> <li> <p>Ajusta os shape_id com base no sentido da viagem, assegurando que a geometria associada corresponda ao trajeto planejado.</p> </li> <li> <p>Processamento dos Dados de Shapes (shapes):</p> </li> <li> <p>Faz um JOIN com a tabela de formas geom\u00e9tricas (subsidio_shapes_geom), recuperando a geometria completa das rotas, assim como os pontos de in\u00edcio e fim para cada trajeto planejado.</p> </li> <li> <p>Sele\u00e7\u00e3o e Ajuste Final:</p> </li> <li>Combina as informa\u00e7\u00f5es processadas das trips e dos shapes, estabelecendo a dire\u00e7\u00e3o do shape (sentido_shape) com base nas condi\u00e7\u00f5es observadas.</li> <li>Adiciona colunas complementares como id_tipo_trajeto, feed_version, e a data/hora atual para registrar a \u00faltima atualiza\u00e7\u00e3o (datetime_ultima_atualizacao).</li> </ul> <p>O resultado final \u00e9 um conjunto de dados consolidado que engloba todas as informa\u00e7\u00f5es planejadas das viagens, associando hor\u00e1rios, trajetos e geometrias. Esse conjunto serve como base para as compara\u00e7\u00f5es com os dados reais de execu\u00e7\u00e3o, permitindo uma an\u00e1lise detalhada da conformidade e do desempenho operacional.</p>"},{"location":"pipelines/listagem_pipelines/monitoramento/apuracao_viagens_v10/#dicas-inserir-todos-os-nomes-das-querys","title":"Dicas: inserir todos os nomes das querys","text":""},{"location":"tabelas/backups/","title":"Processo de Backup","text":"<p>Esta p\u00e1gina descreve o processo utilizado para realizar backups de dados do BigQuery.</p>"},{"location":"tabelas/backups/#1-verificacao-da-quantidade-de-dados","title":"1. Verifica\u00e7\u00e3o da Quantidade de Dados","text":"<p>Antes de realizar o backup, utilizamos a seguinte query para contar o n\u00famero de registros na tabela que ser\u00e1 exportada:</p> <pre><code>SELECT\n    COUNT(*) AS count\nFROM\n    `{project_id}.{dataset_id}.{table_id}`\n</code></pre> <p>Este valor \u00e9 utilizado para exportar todos os dados em um \u00fanico arquivo.</p> <p>Caso a tabela contenha uma coluna de data, tamb\u00e9m coletamos a menor e a maior data dos registros que ser\u00e3o salvos:</p> <pre><code>SELECT\n    MIN(data) AS data_inicio,\n    MAX(data) AS data_fim\nFROM\n    `{project_id}.{dataset_id}.{table_id}`\n</code></pre>"},{"location":"tabelas/backups/#2-exportacao-dos-dados-para-o-google-cloud-storage-gcs","title":"2. Exporta\u00e7\u00e3o dos Dados para o Google Cloud Storage (GCS)","text":"<p>Ap\u00f3s verificar a quantidade de registros, realizamos a exporta\u00e7\u00e3o dos dados da tabela para o GCS utilizando a seguinte query:</p> <pre><code>EXPORT DATA\n  OPTIONS (\n    uri = 'gs://rj-smtr-staging/backup/{dataset_id}/{table_id}/data={data}/{table_id}_00_*.csv',\n    format = 'CSV',\n    header = TRUE,\n    OVERWRITE = TRUE\n  ) AS (\n    SELECT\n      *\n    FROM\n      `{project_id}.{dataset_id}.{table_id}`\n    LIMIT\n      {count}\n)\n</code></pre>"},{"location":"tabelas/backups/#explicacao-dos-parametros","title":"Explica\u00e7\u00e3o dos par\u00e2metros:","text":"<ul> <li>uri: O local de destino no GCS onde os arquivos CSV ser\u00e3o salvos. O caminho segue o padr\u00e3o: <code>gs://rj-smtr-staging/backup/{dataset_id}/{table_id}/data={data}/{table_id}_00_*.csv</code></li> <li>format: O formato do arquivo exportado, que ser\u00e1 CSV.</li> <li>header: Indica que o cabe\u00e7alho das colunas ser\u00e1 inclu\u00eddo no arquivo CSV.</li> <li>OVERWRITE: Permite que arquivos existentes sejam sobrescritos.</li> </ul> <p>Nesta query: - O <code>count</code> \u00e9 o valor obtido na etapa anterior.</p>"},{"location":"tabelas/backups/#3-atualizacao-da-planilha-de-controle","title":"3. Atualiza\u00e7\u00e3o da Planilha de Controle","text":"<p>Ap\u00f3s a exporta\u00e7\u00e3o dos dados, realizamos a atualiza\u00e7\u00e3o de uma planilha de controle no Google Sheets. Esta planilha cont\u00e9m informa\u00e7\u00f5es sobre cada backup realizado, permitindo que tenhamos um registro dos backups.</p> <p>As colunas da planilha s\u00e3o:</p> Coluna Descri\u00e7\u00e3o Data Data em que o backup foi realizado. dataset_id O ID do dataset do BigQuery. table_id O ID da tabela que foi exportada. Local do backup O caminho no GCS onde o backup foi salvo. Descri\u00e7\u00e3o da tabela Descri\u00e7\u00e3o da tabela. Motivo do backup Motivo para a realiza\u00e7\u00e3o do backup. Lista de colunas Colunas que foram exportadas no backup. Data in\u00edcio Menor data dos registros exportados (se aplic\u00e1vel). Data fim Maior data dos registros exportados (se aplic\u00e1vel). <p>Essas informa\u00e7\u00f5es permitem o controle dos backups, garantindo a integridade dos dados e facilitando futuras restaura\u00e7\u00f5es, se necess\u00e1rio.</p>"},{"location":"tabelas/manual_estilo_tabelas/","title":"Manual de Estilo de Modelos e Tabelas","text":"<p>Esta p\u00e1gina \u00e9 baseada no manual de estilo da Base dos Dados</p>"},{"location":"tabelas/manual_estilo_tabelas/#modelos-dbt","title":"Modelos DBT","text":""},{"location":"tabelas/manual_estilo_tabelas/#organizacao-do-diretorio-models","title":"Organiza\u00e7\u00e3o do Diret\u00f3rio models","text":"<p>O diret\u00f3rio <code>queries/models</code> deve ser dividido em pastas referentes aos datasets do BigQuery em que cada tabela ser\u00e1 criada. Cada pasta de dataset pode conter uma subpasta <code>staging</code>, para armazenar os modelos intermedi\u00e1rios para a cria\u00e7\u00e3o das tabelas e views finais. Al\u00e9m disso, cada dataset deve contenter um arquivo schema.yml para a cria\u00e7\u00e3o das descri\u00e7\u00f5es das tabelas, views e colunas.</p> <p>Exemplo:</p> <pre><code>\u2514\u2500\u2500 queries\n\u00a0\u00a0  \u2514\u2500\u2500 models\n\u00a0\u00a0  \u00a0\u00a0 \u2514\u2500\u2500 nome_dataset\n         \u00a0\u00a0 \u251c\u2500\u2500 nome_modelo.sql # instru\u00e7\u00f5es sql para materializa\u00e7\u00e3o de uma tabela ou view\n         \u00a0\u00a0 \u251c\u2500\u2500 schema.yml # estrutura e documenta\u00e7\u00e3o do modelo\n            \u2514\u2500\u2500 staging\n                \u2514\u2500\u2500 nome_modelo_intermediario.sql\n</code></pre>"},{"location":"tabelas/manual_estilo_tabelas/#estruturacao-dos-modelos","title":"Estrutura\u00e7\u00e3o dos Modelos","text":""},{"location":"tabelas/manual_estilo_tabelas/#tabelas-e-datasets","title":"Tabelas e Datasets","text":""},{"location":"tabelas/manual_estilo_tabelas/#nomeacao-de-datasets","title":"Nomea\u00e7\u00e3o de Datasets","text":"<ul> <li> <p>Caso sejam para tabelas de uso geral, os datasets s\u00e3o nomeados de acordo com a categoria dos dados armazenados. Exemplo:</p> <ul> <li><code>bilhetagem</code></li> <li><code>financeiro</code></li> <li><code>subsidio</code></li> </ul> </li> <li> <p>Os datasets tamb\u00e9m podem ser nomeados de forma a indicar a finalidade espec\u00edfica em que os dados s\u00e3o usados Exemplo:</p> <ul> <li><code>validacao_dados_jae</code></li> </ul> </li> <li> <p>Ou com o nome de um dashboard, utilizando o prefixo <code>dashboard_</code> Exemplo:</p> <ul> <li><code>dashboard_subsidio_sppo</code></li> </ul> </li> </ul>"},{"location":"tabelas/manual_estilo_tabelas/#nomeacao-de-tabelas","title":"Nomea\u00e7\u00e3o de Tabelas","text":"<ul> <li> <p>As tabelas devem ser sempre nomeadas no singular</p> </li> <li> <p>Caso a tabela tenha algum qualificador, por exemplo <code>aux</code> e <code>view</code>, ele deve ser colocado como prefixo. Exemplo: <code>aux_gratuidade</code></p> </li> <li> <p>A nomea\u00e7\u00e3o de tabelas n\u00e3o agregadas \u00e9 menos estruturada, devendo apenas indicar claramente qual informa\u00e7\u00e3o que se encontra nela.</p> </li> <li> <p>Para tabelas agregadas, n\u00f3s nomeamos de forma a indicar o nivel de agrega\u00e7\u00e3o do menor para o maior. Exemplo: <code>ordem_pagamento_servico_operador_dia</code></p> <ul> <li>Este exemplo indica uma tabela com os dados das ordens de pagamento, agregados por <code>servico</code> (campo mais espec\u00edfico), <code>operador</code> e <code>dia</code> (campo mais geral)</li> </ul> </li> </ul>"},{"location":"tabelas/manual_estilo_tabelas/#nomeacao-e-tipos-de-colunas","title":"Nomea\u00e7\u00e3o e Tipos de Colunas","text":"<ul> <li>Procurar usar os nomes que j\u00e1 s\u00e3o utilizados. Exemplos: <code>data</code>, <code>servico</code>, <code>modo</code>, <code>id_veiculo</code>.</li> <li>Ser o mais claro e intuitivo poss\u00edvel.</li> <li>O nome das colunas devem ser escritos em snake_case (todas as letras min\u00fasculas e palavras separadas por <code>_</code>).</li> <li>Colunas do tipo booleano devem ter um prefixo <code>indicador_</code>. Exemplo: <code>indicador_transacao_valida</code>.</li> <li>Colunas num\u00e9ricas com ponto flutuante que representam valores financeiros devem utilizar o tipo <code>NUMERIC</code>.</li> <li>Colunas de id devem ser do tipo <code>STRING</code>, exceto se este for o campo de parti\u00e7\u00e3o da tabela.</li> </ul>"},{"location":"tabelas/manual_estilo_tabelas/#ordenamento-de-colunas","title":"Ordenamento de Colunas","text":"<ul> <li>Os primeiros campos devem ser sempre a coluna de parti\u00e7\u00e3o da tabela (se houver) e a chave \u00fanica da tabela, nesta ordem.</li> <li>Caso n\u00e3o tenha chave \u00fanica, as chaves prim\u00e1rias devem ser dispostas em ordem decrescente de abrang\u00eancia (Exemplo: <code>modo</code>, <code>id_servico</code>, <code>id_operador</code>)</li> <li>As pr\u00f3ximas colunas devem ser outras informa\u00e7\u00f5es identificadores em ordem decrescente de abrang\u00eancia.</li> <li>Colunas de <code>id</code>, sua descri\u00e7\u00e3o e outras informa\u00e7\u00f5es relativas a ele devem permanecer agrupadas. Sempre com o <code>id</code> sendo a primeira coluna. Exemplos: <code>id_servico</code>, <code>servico</code>, <code>descricao_servico</code>, <code>id_operador</code>, <code>operador</code></li> <li>Colunas qualitativas devem ser agrupadas por tema e dispostas em ordem decrescente de relev\u00e2ncia.</li> <li>O mesmo deve ser feito para colunas quantitativas, em seguida.</li> <li> <p>Por fim, deve ser inclu\u00eddas as colunas de controle: <code>datetime_captura</code> (se aplic\u00e1vel), <code>datetime_ultima_atualizacao</code>, <code>versao</code></p> </li> <li> <p>Exemplo de ordenamento: <code>data</code> (parti\u00e7\u00e3o) <code>id_transacao</code> (chave \u00fanica) <code>datetime_transacao</code> (identificador temporal) <code>datetime_processamento</code> (identificador temporal) <code>modo</code> (identificador modo) <code>id_consorcio</code> (identificador consorcio) <code>consorcio</code> (identificador consorcio) <code>id_operadora</code> (identificador operadora) <code>operadora</code> (identificador operadora) <code>id_servico_jae</code> (identificador servico) <code>servico_jae</code> (identificador servico) <code>descricao_servico_jae</code> (identificador servico) <code>sentido</code> (identificador sentido) <code>id_veiculo</code> (identificador veiculo) <code>id_validador</code> (identificador validador) <code>id_cliente</code> (identificador cliente) <code>tipo_pagamento</code> (qualitativa) <code>tipo_transacao</code> (qualitativa) <code>tipo_transacao_smtr</code> (qualitativa) <code>tipo_gratuidade</code> (qualitativa) <code>id_tipo_integracao</code> (qualitativa) <code>id_integracao</code> (qualitativa) <code>latitude</code> (qualitativa) <code>longitude</code> (qualitativa) <code>stop_id</code> (qualitativa) <code>stop_lat</code> (qualitativa) <code>stop_lon</code> (qualitativa) <code>valor_transacao</code> (quantitativa) <code>valor_pagamento</code> (quantitativa) <code>datetime_captura</code> (controle) <code>datetime_ultima_atualizacao</code> (controle), <code>versao</code> (controle)  </p> </li> </ul>"},{"location":"tabelas/manual_estilo_tabelas/#descricoes-de-tabelas-e-colunas","title":"Descri\u00e7\u00f5es de tabelas e colunas","text":"<p>As descri\u00e7\u00f5es de tabelas e colunas devem seguir um padr\u00e3o espec\u00edfico para garantir clareza e consist\u00eancia. A estrutura adotada \u00e9 a seguinte:</p> <ul> <li>Descri\u00e7\u00e3o dos dados: Explica\u00e7\u00e3o clara e objetiva sobre o conte\u00fado da coluna ou tabela;</li> <li>Explica\u00e7\u00e3o/Observa\u00e7\u00e3o: Se aplic\u00e1vel, qualquer informa\u00e7\u00e3o adicional relevante deve ser inclu\u00edda entre colchetes em min\u00fasculo (exceto siglas) <code>[]</code>;</li> <li>Unidade de medida: Se aplic\u00e1vel, sempre por \u00faltimo, observadas tamb\u00e9m as regras da se\u00e7\u00e3o espec\u00edfica.</li> </ul> <p>Exemplo:</p> <pre><code>- \"Receita total esperada com base na quilometragem [IRK x km] (R$)\"\n- \"Nome curto da linha operada pelo ve\u00edculo com varia\u00e7\u00e3o de servi\u00e7o [ex.: 010, 011SN, ...]\"\n- \"Par\u00e2metros de remunera\u00e7\u00e3o do subs\u00eddio dos servi\u00e7os de \u00f4nibus [SPPO] por tipo de viagem [descontinuada a partir de 2024-03-01]\"\n</code></pre>"},{"location":"tabelas/manual_estilo_tabelas/#unidades-de-medida","title":"Manual de Estilo","text":"<p>As unidades de medida devem ser registradas na descri\u00e7\u00e3o da coluna entre par\u00eanteses, garantindo clareza e padroniza\u00e7\u00e3o na interpreta\u00e7\u00e3o dos dados. Nossas regras s\u00e3o:</p> <ul> <li>Caso a coluna represente um valor absoluto, utilize apenas a unidade correspondente (ex.: <code>R$</code>, <code>km</code>, <code>min</code>);</li> <li>Se a unidade estiver associada a uma refer\u00eancia, utilize o formato \"Unidade/Refer\u00eancia\" para indicar a rela\u00e7\u00e3o entre grandezas (ex.:<code>R$/km</code>, <code>km/h</code>);</li> <li>Sempre use abrevia\u00e7\u00f5es padronizadas para unidades conforme Sistema Internacional de Unidades (SI), evitando varia\u00e7\u00f5es informais (ex.: <code>h</code> para horas, n\u00e3o <code>hrs</code>);</li> <li>Caso a unidade n\u00e3o seja \u00f3bvia, inclua uma explica\u00e7\u00e3o sucinta entre colchetes.</li> </ul> <p>Exemplo:</p> <pre><code>- \"Receita total aferida [receita tarif\u00e1ria + subsidio pago] (R$)\"\n- \"Valor m\u00e1ximo de subs\u00eddio, conforme tipo de viagem (R$/km)\"\n- \"Dist\u00e2ncia percorrida (km)\"\n</code></pre>"},{"location":"tabelas/manual_estilo_tabelas/#unidades-medida","title":"Unidades de medida","text":""},{"location":"tabelas/manual_estilo_tabelas/#dicionarios","title":"Dicion\u00e1rios","text":"<ul> <li>Sempre que poss\u00edvel e necess\u00e1rio, cada conjunto de dados dever\u00e1 incluir at\u00e9 um dicion\u00e1rio;</li> <li>Para cada tabela, coluna e cobertura temporal, cada chave mapeia unicamente um valor;</li> <li>Chaves n\u00e3o podem ter valores nulos;</li> <li>Dicion\u00e1rios devem cobrir todas as chaves dispon\u00edveis nas tabelas originais.</li> </ul>"},{"location":"tabelas/manual_estilo_tabelas/#cobertura-temporal","title":"Cobertura temporal","text":"<p>Preencher a coluna <code>cobertura_temporal</code> nos metadados de tabela, coluna e chave (em dicion\u00e1rios) segue o seguinte padr\u00e3o.</p> <ul> <li>Formato geral: <code>data_inicial(unidade_temporal)data_final</code><ul> <li><code>data_inicial</code> e <code>data_final</code> est\u00e3o na correspondente unidade temporal.<ul> <li>Exemplo: tabela com unidade <code>ano</code> tem cobertura <code>2005(1)2018</code>.</li> <li>Exemplo: tabela com unidade <code>mes</code> tem cobertura <code>2005-08(1)2018-12</code>.</li> <li>Exemplo: tabela com unidade <code>semana</code> tem cobertura <code>2005-08-01(7)2018-08-31</code>.</li> <li>Exemplo: tabela com unidade <code>dia</code> tem cobertura <code>2005-08-01(1)2018-12-31</code>.</li> </ul> </li> <li>Caso a <code>data_final</code> ainda n\u00e3o tenha sido alcan\u00e7ada:<ul> <li>Exemplo: tabela com unidade <code>ano</code> tem cobertura <code>2005(1)</code>.</li> <li>Exemplo: tabela com unidade <code>mes</code> tem cobertura <code>2005-08(1)</code>.</li> <li>Exemplo: tabela com unidade <code>semana</code> tem cobertura <code>2005-08-01(7)</code>.</li> <li>Exemplo: tabela com unidade <code>dia</code> tem cobertura <code>2005-08-01(1)</code>.</li> </ul> </li> </ul> </li> </ul>"}]}